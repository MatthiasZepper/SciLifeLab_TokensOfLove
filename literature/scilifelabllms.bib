@Article{Juzek2024,
  author        = {Juzek, Tom S. and Ward, Zina B.},
  title         = {Why Does ChatGPT "Delve" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models},
  year          = {2024},
  month         = dec,
  abstract      = {Scientific English is currently undergoing rapid change, with words like "delve," "intricate," and "underscore" appearing far more frequently than just a few years ago. It is widely assumed that scientists' use of large language models (LLMs) is responsible for such trends. We develop a formal, transferable method to characterize these linguistic changes. Application of our method yields 21 focal words whose increased occurrence in scientific abstracts is likely the result of LLM usage. We then pose "the puzzle of lexical overrepresentation": WHY are such words overused by LLMs? We fail to find evidence that lexical overrepresentation is caused by model architecture, algorithm choices, or training data. To assess whether reinforcement learning from human feedback (RLHF) contributes to the overuse of focal words, we undertake comparative model testing and conduct an exploratory online study. While the model testing is consistent with RLHF playing a role, our experimental results suggest that participants may be reacting differently to "delve" than to other focal words. With LLMs quickly becoming a driver of global language change, investigating these potential sources of lexical overrepresentation is important. We note that while insights into the workings of LLMs are within reach, a lack of transparency surrounding model development remains an obstacle to such research.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2412.11385},
  eprint        = {2412.11385},
  file          = {:Juzek2024 - Why Does ChatGPT _Delve_ so Much_ Exploring the Sources of Lexical Overrepresentation in Large Language Models.pdf:PDF:http\://arxiv.org/pdf/2412.11385v1},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Misc{Belanger2025,
  author       = {Ashley Belanger},
  howpublished = {Ars Technica},
  month        = jan,
  title        = {Torrenting from a corporate laptop doesn’t feel right: Meta emails unsealed},
  year         = {2025},
  abstract     = {Newly unsealed emails allegedly provide the "most damning evidence" yet against Meta in a copyright case raised by book authors alleging that Meta illegally trained its AI models on pirated books.

Last month, Meta admitted to torrenting a controversial large dataset known as LibGen, which includes tens of millions of pirated books. But details around the torrenting were murky until yesterday, when Meta's unredacted emails were made public for the first time. The new evidence showed that Meta torrented "at least 81.7 terabytes of data across multiple shadow libraries through the site Anna’s Archive, including at least 35.7 terabytes of data from Z-Library and LibGen," the authors' court filing said. And "Meta also previously torrented 80.6 terabytes of data from LibGen."

"The magnitude of Meta’s unlawful torrenting scheme is astonishing," the authors' filing alleged, insisting that "vastly smaller acts of data piracy—just .008 percent of the amount of copyrighted works Meta pirated—have resulted in Judges referring the conduct to the US Attorneys’ office for criminal investigation."},
  url          = {https://arstechnica.com/tech-policy/2025/02/meta-torrented-over-81-7tb-of-pirated-books-to-train-ai-authors-say/},
}

@Article{Zhang2024,
  author    = {Zhang, Manshu and Wu, Liming and Yang, Tao and Zhu, Bing and Liu, Yangai},
  journal   = {Surfaces and Interfaces},
  title     = {RETRACTED: The three-dimensional porous mesh structure of Cu-based metal-organic-framework - Aramid cellulose separator enhances the electrochemical performance of lithium metal anode batteries},
  year      = {2024},
  issn      = {2468-0230},
  month     = mar,
  pages     = {104081},
  volume    = {46},
  doi       = {10.1016/j.surfin.2024.104081},
  publisher = {Elsevier BV},
}

@Article{Blum2023,
  author    = {Blum, Moritz},
  journal   = {Journal of Cardiac Failure},
  title     = {ChatGPT Produces Fabricated References and Falsehoods When Used for Scientific Literature Search},
  year      = {2023},
  issn      = {1071-9164},
  month     = sep,
  number    = {9},
  pages     = {1332--1334},
  volume    = {29},
  comment   = {doi: 10.1016/j.cardfail.2023.06.015},
  doi       = {10.1016/j.cardfail.2023.06.015},
  publisher = {Elsevier},
  url       = {https://doi.org/10.1016/j.cardfail.2023.06.015},
}

@Misc{Marcus2023,
  author       = {Gary Marcus},
  howpublished = {Marcus on AI},
  month        = feb,
  note         = {https://garymarcus.substack.com/p/what-google-should-really-be-worried},
  title        = {What Google Should Really Be Worried About},
  year         = {2023},
  url          = {https://garymarcus.substack.com/p/what-google-should-really-be-worried},
}

@Misc{Holmer2025,
  author       = {Freya Holmér},
  howpublished = {YouTube},
  month        = jan,
  note         = {https://www.youtube.com/watch?v=-opBifFfsMY},
  title        = {Generative AI is a Parasitic Cancer},
  year         = {2025},
  url          = {https://www.youtube.com/watch?v=-opBifFfsMY},
}

@Article{Kobak2024,
  author        = {Kobak, Dmitry and González-Márquez, Rita and Horvát, Emőke-Ágnes and Lause, Jan},
  title         = {Delving into ChatGPT usage in academic writing through excess vocabulary},
  year          = {2024},
  month         = jun,
  abstract      = {Recent large language models (LLMs) can generate and revise text with human-level performance, and have been widely commercialized in systems like ChatGPT. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists have been using them to assist their scholarly writing. How wide-spread is LLM usage in the academic literature currently? To answer this question, we use an unbiased, large-scale approach, free from any assumptions on academic LLM usage. We study vocabulary changes in 14 million PubMed abstracts from 2010-2024, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. Our analysis based on excess words usage suggests that at least 10% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, and was as high as 30% for some PubMed sub-corpora. We show that the appearance of LLM-based writing assistants has had an unprecedented impact in the scientific literature, surpassing the effect of major world events such as the Covid pandemic.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2406.07016},
  eprint        = {2406.07016},
  file          = {:http\://arxiv.org/pdf/2406.07016v2:PDF},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Digital Libraries (cs.DL), Social and Information Networks (cs.SI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Comment{jabref-meta: databaseType:bibtex;}
