@Article{Juzek2024,
  author        = {Juzek, Tom S. and Ward, Zina B.},
  title         = {Why Does ChatGPT "Delve" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models},
  year          = {2024},
  month         = dec,
  abstract      = {Scientific English is currently undergoing rapid change, with words like "delve," "intricate," and "underscore" appearing far more frequently than just a few years ago. It is widely assumed that scientists' use of large language models (LLMs) is responsible for such trends. We develop a formal, transferable method to characterize these linguistic changes. Application of our method yields 21 focal words whose increased occurrence in scientific abstracts is likely the result of LLM usage. We then pose "the puzzle of lexical overrepresentation": WHY are such words overused by LLMs? We fail to find evidence that lexical overrepresentation is caused by model architecture, algorithm choices, or training data. To assess whether reinforcement learning from human feedback (RLHF) contributes to the overuse of focal words, we undertake comparative model testing and conduct an exploratory online study. While the model testing is consistent with RLHF playing a role, our experimental results suggest that participants may be reacting differently to "delve" than to other focal words. With LLMs quickly becoming a driver of global language change, investigating these potential sources of lexical overrepresentation is important. We note that while insights into the workings of LLMs are within reach, a lack of transparency surrounding model development remains an obstacle to such research.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2412.11385},
  eprint        = {2412.11385},
  file          = {:Juzek2024 - Why Does ChatGPT _Delve_ so Much_ Exploring the Sources of Lexical Overrepresentation in Large Language Models.pdf:PDF:http\://arxiv.org/pdf/2412.11385v1},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Misc{Belanger2025,
  author       = {Ashley Belanger},
  howpublished = {Ars Technica},
  month        = jan,
  title        = {Torrenting from a corporate laptop doesn’t feel right: Meta emails unsealed},
  year         = {2025},
  abstract     = {Newly unsealed emails allegedly provide the "most damning evidence" yet against Meta in a copyright case raised by book authors alleging that Meta illegally trained its AI models on pirated books.

Last month, Meta admitted to torrenting a controversial large dataset known as LibGen, which includes tens of millions of pirated books. But details around the torrenting were murky until yesterday, when Meta's unredacted emails were made public for the first time. The new evidence showed that Meta torrented "at least 81.7 terabytes of data across multiple shadow libraries through the site Anna’s Archive, including at least 35.7 terabytes of data from Z-Library and LibGen," the authors' court filing said. And "Meta also previously torrented 80.6 terabytes of data from LibGen."

"The magnitude of Meta’s unlawful torrenting scheme is astonishing," the authors' filing alleged, insisting that "vastly smaller acts of data piracy—just .008 percent of the amount of copyrighted works Meta pirated—have resulted in Judges referring the conduct to the US Attorneys’ office for criminal investigation."},
  url          = {https://arstechnica.com/tech-policy/2025/02/meta-torrented-over-81-7tb-of-pirated-books-to-train-ai-authors-say/},
}

@Article{Zhang2024,
  author    = {Zhang, Manshu and Wu, Liming and Yang, Tao and Zhu, Bing and Liu, Yangai},
  journal   = {Surfaces and Interfaces},
  title     = {RETRACTED: The three-dimensional porous mesh structure of Cu-based metal-organic-framework - Aramid cellulose separator enhances the electrochemical performance of lithium metal anode batteries},
  year      = {2024},
  issn      = {2468-0230},
  month     = mar,
  pages     = {104081},
  volume    = {46},
  doi       = {10.1016/j.surfin.2024.104081},
  publisher = {Elsevier BV},
}

@misc{howard2018universal,
    title={Universal Language Model Fine-tuning for Text Classification},
    author={Jeremy Howard and others},
    year={2018},
    eprint={1801.06146},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and others},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{sun2019finetune,
    title={How to Fine-Tune BERT for Text Classification?},
    author={Chi Sun and others},
    year={2019},
    eprint={1905.05583},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{Gray2017GPUKF,
  title={GPU Kernels for Block-Sparse Weights},
  author={Scott Gray and others},
  year={2017}
}

@misc{yang2019xlnet,
    title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
    author={Zhilin Yang and others},
    year={2019},
    eprint={1906.08237},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and others},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{shoeybi2019megatronlm,
    title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
    author={Mohammad Shoeybi and others},
    year={2019},
    eprint={1909.08053},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{hochreiter1997long,
  added-at = {2016-11-15T08:49:43.000+0100},
  author = {Hochreiter, Sepp and others},
  biburl = {https://www.bibsonomy.org/bibtex/2a4a80026d24955b267cae636aa8abe4a/dallmann},
  interhash = {0692b471c4b9ae65d00affebc09fb467},
  intrahash = {a4a80026d24955b267cae636aa8abe4a},
  journal = {Neural computation},
  keywords = {lstm rnn},
  number = 8,
  pages = {1735--1780},
  publisher = {MIT Press},
  timestamp = {2016-11-15T08:49:43.000+0100},
  title = {Long short-term memory},
  volume = 9,
  year = 1997
}

@misc{wang2018glue,
    title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
    author={Alex Wang and others},
    year={2018},
    eprint={1804.07461},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{peters2018deep,
    title={Deep contextualized word representations},
    author={Matthew E. Peters and others},
    year={2018},
    eprint={1802.05365},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{wordPiece,
    title	= {Japanese and Korean Voice Search},
    author	= {Mike Schuster and others},
    year	= {2012},
    booktitle	= {International Conference on Acoustics, Speech and Signal Processing},
    pages	= {5149--5152}
}

@incollection{mikolov2013,
    title = {Distributed Representations of Words and Phrases and their Compositionality},
    author = {Mikolov, Tomas and others},
    booktitle = {Advances in Neural Information Processing Systems 26},
    editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
    pages = {3111--3119},
    year = {2013},
    publisher = {Curran Associates, Inc.},
    url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf}
}

@inproceedings{penningtonglove,
    title = "{G}love: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      others",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford and others},
  year={2018}
}

@inproceedings{mikolov2018advances,
  title={Advances in Pre-Training Distributed Word Representations},
  author={Mikolov, Tomas and others},
  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@Article{Blum2023,
  author    = {Blum, Moritz},
  journal   = {Journal of Cardiac Failure},
  title     = {ChatGPT Produces Fabricated References and Falsehoods When Used for Scientific Literature Search},
  year      = {2023},
  issn      = {1071-9164},
  month     = sep,
  number    = {9},
  pages     = {1332--1334},
  volume    = {29},
  comment   = {doi: 10.1016/j.cardfail.2023.06.015},
  doi       = {10.1016/j.cardfail.2023.06.015},
  publisher = {Elsevier},
  url       = {https://doi.org/10.1016/j.cardfail.2023.06.015},
}

@Misc{Marcus2023,
  author       = {Gary Marcus},
  howpublished = {Marcus on AI},
  month        = feb,
  title        = {What Google Should Really Be Worried About},
  year         = {2023},
  url          = {https://garymarcus.substack.com/p/what-google-should-really-be-worried},
}

@Misc{Holmer2025,
  author       = {Freya Holmér},
  howpublished = {YouTube},
  month        = jan,
  title        = {Generative AI is a Parasitic Cancer},
  year         = {2025},
  url          = {https://www.youtube.com/watch?v=-opBifFfsMY},
}

@Article{Kobak2024,
  author        = {Kobak, Dmitry and González-Márquez, Rita and Horvát, Emőke-Ágnes and Lause, Jan},
  title         = {Delving into ChatGPT usage in academic writing through excess vocabulary},
  year          = {2024},
  month         = jun,
  abstract      = {Recent large language models (LLMs) can generate and revise text with human-level performance, and have been widely commercialized in systems like ChatGPT. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists have been using them to assist their scholarly writing. How wide-spread is LLM usage in the academic literature currently? To answer this question, we use an unbiased, large-scale approach, free from any assumptions on academic LLM usage. We study vocabulary changes in 14 million PubMed abstracts from 2010-2024, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. Our analysis based on excess words usage suggests that at least 10\% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, and was as high as 30\% for some PubMed sub-corpora. We show that the appearance of LLM-based writing assistants has had an unprecedented impact in the scientific literature, surpassing the effect of major world events such as the Covid pandemic.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2406.07016},
  eprint        = {2406.07016},
  file          = {:http\://arxiv.org/pdf/2406.07016v2:PDF},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), Digital Libraries (cs.DL), Social and Information Networks (cs.SI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@article{Radford2019,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@Article{Solaiman2019,
  author        = {Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and McCain, Miles and Newhouse, Alex and Blazakis, Jason and McGuffie, Kris and Wang, Jasmine},
  title         = {Release Strategies and the Social Impacts of Language Models},
  year          = {2019},
  month         = aug,
  abstract      = {Large language models have a range of beneficial uses: they can assist in prose, poetry, and programming; analyze dataset biases; and more. However, their flexibility and generative capabilities also raise misuse concerns. This report discusses OpenAI's work related to the release of its GPT-2 language model. It discusses staged release, which allows time between model releases to conduct risk and benefit analyses as model sizes increased. It also discusses ongoing partnership-based research and provides recommendations for better coordination and responsible publication in AI.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1908.09203},
  eprint        = {1908.09203},
  file          = {:Solaiman2019 - Release Strategies and the Social Impacts of Language Models.pdf:PDF:http\://arxiv.org/pdf/1908.09203v2},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computers and Society (cs.CY), FOS: Computer and information sciences, I.2; I.2.7; K.4},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Comment{jabref-meta: databaseType:bibtex;}
