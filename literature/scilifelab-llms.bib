@Article{Juzek2024,
  author        = {Juzek, Tom S. and Ward, Zina B.},
  title         = {Why Does ChatGPT "Delve" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models},
  year          = {2024},
  month         = dec,
  abstract      = {Scientific English is currently undergoing rapid change, with words like "delve," "intricate," and "underscore" appearing far more frequently than just a few years ago. It is widely assumed that scientists' use of large language models (LLMs) is responsible for such trends. We develop a formal, transferable method to characterize these linguistic changes. Application of our method yields 21 focal words whose increased occurrence in scientific abstracts is likely the result of LLM usage. We then pose "the puzzle of lexical overrepresentation": WHY are such words overused by LLMs? We fail to find evidence that lexical overrepresentation is caused by model architecture, algorithm choices, or training data. To assess whether reinforcement learning from human feedback (RLHF) contributes to the overuse of focal words, we undertake comparative model testing and conduct an exploratory online study. While the model testing is consistent with RLHF playing a role, our experimental results suggest that participants may be reacting differently to "delve" than to other focal words. With LLMs quickly becoming a driver of global language change, investigating these potential sources of lexical overrepresentation is important. We note that while insights into the workings of LLMs are within reach, a lack of transparency surrounding model development remains an obstacle to such research.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2412.11385},
  eprint        = {2412.11385},
  file          = {:Juzek2024 - Why Does ChatGPT _Delve_ so Much_ Exploring the Sources of Lexical Overrepresentation in Large Language Models.pdf:PDF:http\://arxiv.org/pdf/2412.11385v1},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
}

@Misc{Belanger2025,
  author       = {Ashley Belanger},
  howpublished = {Ars Technica},
  month        = jan,
  title        = {Torrenting from a corporate laptop doesn’t feel right: Meta emails unsealed},
  year         = {2025},
  abstract     = {Newly unsealed emails allegedly provide the "most damning evidence" yet against Meta in a copyright case raised by book authors alleging that Meta illegally trained its AI models on pirated books.

Last month, Meta admitted to torrenting a controversial large dataset known as LibGen, which includes tens of millions of pirated books. But details around the torrenting were murky until yesterday, when Meta's unredacted emails were made public for the first time. The new evidence showed that Meta torrented "at least 81.7 terabytes of data across multiple shadow libraries through the site Anna’s Archive, including at least 35.7 terabytes of data from Z-Library and LibGen," the authors' court filing said. And "Meta also previously torrented 80.6 terabytes of data from LibGen."

"The magnitude of Meta’s unlawful torrenting scheme is astonishing," the authors' filing alleged, insisting that "vastly smaller acts of data piracy—just .008 percent of the amount of copyrighted works Meta pirated—have resulted in Judges referring the conduct to the US Attorneys’ office for criminal investigation."},
  url          = {https://arstechnica.com/tech-policy/2025/02/meta-torrented-over-81-7tb-of-pirated-books-to-train-ai-authors-say/},
}

@Article{Zhang2024,
  author    = {Zhang, Manshu and Wu, Liming and Yang, Tao and Zhu, Bing and Liu, Yangai},
  journal   = {Surfaces and Interfaces},
  title     = {RETRACTED: The three-dimensional porous mesh structure of Cu-based metal-organic-framework - Aramid cellulose separator enhances the electrochemical performance of lithium metal anode batteries},
  year      = {2024},
  issn      = {2468-0230},
  month     = mar,
  pages     = {104081},
  volume    = {46},
  doi       = {10.1016/j.surfin.2024.104081},
  publisher = {Elsevier BV},
}

@Article{Blum2023,
  author    = {Blum, Moritz},
  journal   = {Journal of Cardiac Failure},
  title     = {ChatGPT Produces Fabricated References and Falsehoods When Used for Scientific Literature Search},
  year      = {2023},
  issn      = {1071-9164},
  month     = sep,
  number    = {9},
  pages     = {1332--1334},
  volume    = {29},
  comment   = {doi: 10.1016/j.cardfail.2023.06.015},
  doi       = {10.1016/j.cardfail.2023.06.015},
  publisher = {Elsevier},
  url       = {https://doi.org/10.1016/j.cardfail.2023.06.015},
}

@Comment{jabref-meta: databaseType:bibtex;}
